{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ebaff1-0fd6-44ed-874e-dcba53444836",
   "metadata": {},
   "source": [
    "Combine all outputs across multiple imaging batches into a single file and produce segmentation projections for manual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837ac206-6fb9-43b9-b12a-4ef129bfc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD CUSTOM PATH ###\n",
    "path_to_quant = '//home/gridsan/djuna/homer/github/confocalQuant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902d8a39-ee29-4ce8-8edf-a06495a2ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/djuna/.local/lib/python3.8/site-packages/pydantic/_migration.py:281: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from aicsimageio import AICSImage\n",
    "from cellpose import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.segmentation import find_boundaries\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(path_to_quant)\n",
    "from confocalQuant.segmentation import get_czi_files, hide_masks, gamma_correct_image, extract_channels, float_to_int\n",
    "from confocalQuant.plotting import get_out_files, add_metadata, is_string_present, return_results, filter_data, get_id_data\n",
    "from confocalQuant.quantification import concatenate_Y\n",
    "from confocalQuant.image import save_mean_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d4039-198a-4e28-9bdc-fb3c31d7404d",
   "metadata": {},
   "source": [
    "### 1. Create metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfacd2e-7bd4-424a-8ca8-bc2e54467f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '/home/gridsan/djuna/homer/github/confocalQuant/'\n",
    "dirs = np.array(os.listdir('../'))\n",
    "out_dirs = dirs[['neuron' in x for x in dirs]]\n",
    "in_dirs = [x.split('_out')[0] for x in out_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6923a009-3e49-463e-846d-912f21f60427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 94.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# combine all file info\n",
    "all_data = []\n",
    "\n",
    "for i in tqdm(range(len(in_dirs))):\n",
    "    im_path_root = parent_path + 'data/' + in_dirs[i]\n",
    "    out_path_root = parent_path + 'outs/' + out_dirs[i]\n",
    "    \n",
    "    in_file_names = get_czi_files(im_path_root)\n",
    "    out_file_names = get_out_files(out_path_root)\n",
    "    \n",
    "    df = pd.DataFrame([x.split('.')[0] for x in in_file_names])\n",
    "    df.columns = ['filename']\n",
    "    df['ID'] = range(len(in_file_names))\n",
    "    df['batch'] = in_dirs[i]\n",
    "    wellname = [x.split('-')[0] for x in df['filename']]\n",
    "    df['well_name'] = wellname\n",
    "    dictionary = dict(zip([int(x.split('_')[1].split('.')[0]) for x in out_file_names], out_file_names))\n",
    "    df['slurm_name'] = [dictionary[x] for x in df['ID']]\n",
    "    \n",
    "    add_metadata(df, im_path_root+'/temp.csv')\n",
    "    \n",
    "    all_data.append(df)\n",
    "    \n",
    "im_data = pd.DataFrame(np.vstack(all_data))\n",
    "im_data.columns = ['filename', 'fileID', 'batch', 'well_name', 'slurm_file', 'treatment', 'line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea586386-a497-48d3-a0d2-5eaa9511a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fileID</th>\n",
       "      <th>batch</th>\n",
       "      <th>well_name</th>\n",
       "      <th>slurm_file</th>\n",
       "      <th>treatment</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C10</td>\n",
       "      <td>0</td>\n",
       "      <td>neuronbatch10132023_cellrox</td>\n",
       "      <td>C10</td>\n",
       "      <td>slurm-24409544_0.out</td>\n",
       "      <td>DGATi</td>\n",
       "      <td>Y622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2</td>\n",
       "      <td>1</td>\n",
       "      <td>neuronbatch10132023_cellrox</td>\n",
       "      <td>C2</td>\n",
       "      <td>slurm-24409544_1.out</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>Y622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3</td>\n",
       "      <td>2</td>\n",
       "      <td>neuronbatch10132023_cellrox</td>\n",
       "      <td>C3</td>\n",
       "      <td>slurm-24409544_2.out</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>Y622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4</td>\n",
       "      <td>3</td>\n",
       "      <td>neuronbatch10132023_cellrox</td>\n",
       "      <td>C4</td>\n",
       "      <td>slurm-24409544_3.out</td>\n",
       "      <td>CDP-choline</td>\n",
       "      <td>Y622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5</td>\n",
       "      <td>4</td>\n",
       "      <td>neuronbatch10132023_cellrox</td>\n",
       "      <td>C5</td>\n",
       "      <td>slurm-24409544_4.out</td>\n",
       "      <td>CDP-choline</td>\n",
       "      <td>Y622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename fileID                        batch well_name  \\\n",
       "0      C10      0  neuronbatch10132023_cellrox       C10   \n",
       "1       C2      1  neuronbatch10132023_cellrox        C2   \n",
       "2       C3      2  neuronbatch10132023_cellrox        C3   \n",
       "3       C4      3  neuronbatch10132023_cellrox        C4   \n",
       "4       C5      4  neuronbatch10132023_cellrox        C5   \n",
       "\n",
       "             slurm_file    treatment  line  \n",
       "0  slurm-24409544_0.out        DGATi  Y622  \n",
       "1  slurm-24409544_1.out      vehicle  Y622  \n",
       "2  slurm-24409544_2.out      vehicle  Y622  \n",
       "3  slurm-24409544_3.out  CDP-choline  Y622  \n",
       "4  slurm-24409544_4.out  CDP-choline  Y622  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e269d2-068b-4ddf-a8c9-f90a0c24f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529/529 [00:00<00:00, 1571.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# add info on whether job finished runnning\n",
    "res = []\n",
    "for i in tqdm(range(im_data.shape[0])):\n",
    "    file = '../'+im_data['batch'][i]+'_out/' + im_data['slurm_file'][i]\n",
    "    res.append(is_string_present(file, 'done'))\n",
    "\n",
    "im_data['job_done'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c07879-6faa-4035-8a96-fc0aa5a0434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unique image ID\n",
    "np.random.seed(5)\n",
    "im_data['unique_image_ID'] = [np.random.randint(10**9, 10**10) for x in range(im_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb81fc1b-6bbb-41e1-b93c-0fc4d3fb8854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a few checks\n",
    "im_data[np.invert(im_data['job_done'])]\n",
    "random_10_digit_number = im_data['unique_image_ID']\n",
    "len(np.unique(random_10_digit_number))==len(random_10_digit_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ffe1cf-5ca0-4446-aecf-57142729bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'keep' column to populate later\n",
    "im_data['keep'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0035e1d-1d30-45e5-85c7-fad6ce868d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True]), array([529]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(im_data['job_done'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea443cf-0fe3-4bc5-b0b4-eef4781e379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fileID</th>\n",
       "      <th>batch</th>\n",
       "      <th>well_name</th>\n",
       "      <th>slurm_file</th>\n",
       "      <th>treatment</th>\n",
       "      <th>line</th>\n",
       "      <th>job_done</th>\n",
       "      <th>unique_image_ID</th>\n",
       "      <th>keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, fileID, batch, well_name, slurm_file, treatment, line, job_done, unique_image_ID, keep]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data[im_data['job_done']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98cb4bd6-c7b6-4fba-bd97-682ed4a97667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that these IDs are consistent with the previous im_data file and that the new IDs are different\n",
    "im_data_prev = pd.read_csv('./im_data.csv')\n",
    "np.unique([x in set( np.array(im_data_prev['unique_image_ID'])) for x in im_data['unique_image_ID'][389:]])\n",
    "np.array_equal(np.array(im_data['unique_image_ID'][:389]), np.array(im_data_prev['unique_image_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc7995e-f46e-4d89-9925-22d7bce2b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/djuna/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py:2323: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "im_data.to_csv('./im_data_with1108.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6718f271-3d0c-4d6a-8a50-a8f3f83c52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data = im_data[[x in set(['neuronbatch11082023_mitohealth', 'neuronbatch11082023_cellrox_bodipy']) for x in im_data['batch']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10ab1e5-d981-4bc6-820e-fc09628ce033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afe7fc-f7c7-4c47-a2b9-e7a1560c7b74",
   "metadata": {},
   "source": [
    "### 2. add the Y_data to this datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c507b7e-2974-4bde-9b2b-0a7a444c6b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [05:06<00:00,  4.51s/it]\n",
      "100%|██████████| 72/72 [05:28<00:00,  4.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# make dictionaries\n",
    "x, y = np.unique(im_data['batch'], return_counts=True)\n",
    "Nfiles_dict = dict(zip(x,y))\n",
    "batches = np.unique(im_data['batch'])\n",
    "colnames = pd.read_csv('colnames.csv')\n",
    "colnames_dict = dict(zip(list(colnames['batch']), ([[x.split(\"'\")[1] for x in y.split(',')] for y in colnames['colnames']])))\n",
    "list_of_dfs = [(_, group) for _, group in im_data.groupby('batch')]\n",
    "id_dicts = [dict(zip(x[1]['fileID'], x[1]['unique_image_ID'])) for x in list_of_dfs]\n",
    "names = [x[0] for x in list_of_dfs]\n",
    "id_dicts_per_batch = dict(zip(names, id_dicts))\n",
    "\n",
    "# concat per cell Y info\n",
    "res = []\n",
    "start = 0\n",
    "end = 0\n",
    "s_index = np.empty(im_data.shape[0])\n",
    "e_index = np.empty(im_data.shape[0])\n",
    "im_index = 0\n",
    "\n",
    "for i in (range(len(batches))):\n",
    "    \n",
    "    # load data per batch\n",
    "    batch = batches[i]\n",
    "    directory = '../' + batch +'_out/'\n",
    "    path_to_sbatch_file = glob.glob(directory+'*.sbatch')[0]\n",
    "    mat, masks, Y, Ncells, Nzi, cells_per_job, zi_per_job = return_results(path_to_sbatch_file,  '../../')\n",
    "   \n",
    "    # extract Y per batch\n",
    "    Nfiles = Nfiles_dict[batch]\n",
    "    colnames = colnames_dict[batch]\n",
    "    Y_extracted = concatenate_Y(Nfiles, Y, cells_per_job, Ncells, colnames)\n",
    "    id_d = id_dicts_per_batch[batch]\n",
    "    Y_extracted['unique_image_ID'] = [id_d[int(x)] for x in Y_extracted['ID']]\n",
    "    Y_extracted['NeuN_per_point'] = Y_extracted['NeuN']/Y_extracted['Npoints']\n",
    "    Y_extracted['DAPI_per_point'] = Y_extracted['DAPI']/Y_extracted['Npoints']\n",
    "\n",
    "    # filter and append Y per batch\n",
    "    Y_filtered = filter_data(Y_extracted, 'NeuN_per_point', 'DAPI_per_point', 'cellvolume', 'wellname', lower_thresh_vol = 200, upper_thresh_vol = 7000, C_nuc=2, C_soma=1.25, C_nuc_upper=3, plot=False)\n",
    "    Y_extracted['keep_cell'] = [x in set(Y_filtered.index) for x in Y_extracted.index]\n",
    "    res.append(Y_extracted)\n",
    "    \n",
    "    # plot image per ID per batch\n",
    "    IDs = list(id_d.keys())\n",
    "    for ID in tqdm(range(len(IDs))):\n",
    "        save_mean_proj(ID, zi_per_job, Nzi, mat, masks, Y_extracted, Y_filtered, id_d)\n",
    "    \n",
    "\n",
    "# concatenate across all batches\n",
    "cell_data = pd.concat(res, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb7be2d6-3388-488e-bc5b-bb426ceeb48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/djuna/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py:2323: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "cell_data.to_csv('./cell_data_only1108.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356939d-49be-49a1-a824-cd035896e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload images to labelbox.com to determine which images to keep \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f667d-52ae-469a-a74e-c5f7800fc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "find ./segmentations -type f -newermt 2023-12-01 ! -newermt 2023-01-02 -exec tar -rvf output_files_created_on_2023-01-01.tar.gz {} +\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
